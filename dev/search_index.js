var documenterSearchIndex = {"docs":
[{"location":"Reference/","page":"Function Reference","title":"Function Reference","text":"CurrentModule = ROCKS","category":"page"},{"location":"Reference/","page":"Function Reference","title":"Function Reference","text":"","category":"page"},{"location":"Reference/","page":"Function Reference","title":"Function Reference","text":"Modules = [ROCKS]","category":"page"},{"location":"Reference/#ROCKS.BCDiag","page":"Function Reference","title":"ROCKS.BCDiag","text":"BCDiag\n\nA structure of diagnostic properties of a Binary Classifier.\n\nFacilitates summary plots and tables.\n\n\n\n\n\n","category":"type"},{"location":"Reference/#ROCKS.accuracyplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.accuracyplot","text":"accuracyplot(x::BCDiag; util=[1, 0, 0, 1])\n\nUsing util values for [TP, FN, FP, TN], produce accuracy plot and its [max, argmax, argdep]. Default util values of [1, 0, 0, 1] gives the standard accuracy value of (TP+TN)/N.\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.bcdiag-Tuple{BitVector, Vector{T} where T}","page":"Function Reference","title":"ROCKS.bcdiag","text":"bcdiag(target, pred; groups = 100, rev = true, tie = 1e-6)\n\nPerform diagnostics of a binary classifier. target is a 2 level categorical variable, pred is probability of class 1. groups is the number of bins to use for plotting/printing. rev = true orders pred from high to low. tie is the tolerance of pred where values are considered tied.\n\nReturns a BCDiag struct which can be used for plotting or printing:\n\nbiasplot is calibration plot of target response rate vs. pred response rate\nksplot produces ksplot of cumulative distributions\nrocplot plots the Receiver Operating Characteristics curve\naccuracyplot plots the accuracy curve with adjustable utility\nliftcurve is the lift curve\ncumliftsurve is the cumulative lift surve\nliftable is the lift table as a DataFrame\ncumliftable is the cumulative lift table as a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.biasplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.biasplot","text":"biasplot(x::BCDiag)\n\nreturns a bias calibration plot of x - actual response vs. predicted response\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.concordance","page":"Function Reference","title":"ROCKS.concordance","text":"concordance(class, var, tie)\n\nComputes concordant, tied and discordant pairs. class can be either a BitVector or a 2 level categorical target variable in which case true is defined by the last value in sorted sequence. var is a Vector of predictor, same length as class, tie (optional) can be a number (default is 1e-6) that defines a tied region, or it can be a function that when called with a scalar value will return a tuple of lower bound and upper bound of a tied region, useful when you want to do percentage tied region for instance.\n\nPair-wise comparison between class 1 with class 0 values are made as follows:\n\nclass 1 value > class 0 value is Concordant\nclass 1 value â‰ˆ class 0 value (within tie) is Tied\nclass 1 value < class 0 value is Discordant\n\nReturns:\n\nconcordant, number of concordant comparisons\ntied, number of tied comparisons\ndiscordant, number of discordant comparisons\nauroc, or C, is (Concordant + 0.5Tied) / Total comparisons; same as numeric integration of ROC curve\ngini, 2C-1, also known as Somer's D, is (Concordant - Discordant) / Total comparisons\n\nConcordance calculation is the same as numeric integration of the ROC curve, but it allows for fuzzy tied regions which can be useful.\n\nNote:\n\nGoodman-Kruskal Gamma is (Concordant - Discordant) / (Concordant + Discordant)\nKendall's Tau is (Concordant - Discordant) / (0.5 x Total count x (Total count - 1))\n\n\n\n\n\n","category":"function"},{"location":"Reference/#ROCKS.concordance-Tuple{BitVector, Vector{T} where T, Function}","page":"Function Reference","title":"ROCKS.concordance","text":"concordance(class::BitVector, var::Vector, tie::Function)\n\nConcordance calculation with a function to define tied region. More generally flexible when comparing, e.g., income of two groups, where the tied region is not constant but is a percentage of the income for instance.\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.cumliftable-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.cumliftable","text":"cumliftable(x::BCDiag)\n\nreturns a cumulative lift table of x as a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.cumliftcurve-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.cumliftcurve","text":"cumliftcurve(x::BCDiag)\n\nreturns a cumulative lift curve plot of x - cumulative actual and predicted vs. depth\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.ksplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.ksplot","text":"ksplot(x::BCDiag)\n\nreturns a KS plot of x - CDF1 (True Positive) and CDF0 (False Positive) versus depth\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.kstest-Tuple{BitVector, Vector{T} where T}","page":"Function Reference","title":"ROCKS.kstest","text":"kstest(class, var; rev = true)\n\nCalculate empirical 2 sample Kolmogorov-Smirnov statistic and its location. class is a 2 level categorical variable, var is the distribution to analyze.\n\nReturns:\n\nn, total number of observations\nn1, number of observations of class 1\nn0, number of observations of class 0\nbaserate, incidence rate of class 1\nks, the maximum separation between the two cumulative distributions\nksarg, the value of var at which maximum separation is achieved\nksdep, depth of ksarg in the sorted values of var\n\nrev = true counts depth from high value towards low value\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.liftable-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.liftable","text":"liftable(x::BCDiag)\n\nreturns a lift table of x as a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.liftcurve-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.liftcurve","text":"liftcurve(x::BCDiag)\n\nreturns a lift curve plot of x - actual and predicted versus depth\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.ranks-Tuple{Vector{T} where T}","page":"Function Reference","title":"ROCKS.ranks","text":"ranks(x; groups = 10, rank = tiedrank, rev = false)\n\nReturn a variable which bins x into groups number of bins. The rank keyword allows different ranking method; use rev = true to reverse sort so that small bin number is large value of x. Missing values are assigned to group missing.\n\nDefault values of rank = tiedrank and rev = false results in similar grouping as SAS PROC RANK groups=n tied=mean.\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.rocplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.rocplot","text":"rocplot(x::BCDiag)\n\nreturns a ROC plot of x - CDF1 (True Positive) vs. CDF0 (False Positive)\n\n\n\n\n\n","category":"method"},{"location":"man/bcdiag/#Binary-Classifierr-Diagnostics","page":"Plots","title":"Binary Classifierr Diagnostics","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"While kstest and roc provide diagnostic measures for comparing model performance, when there is a model of interest, it is likely that we need to produce many graphs and table to understand and document its performance, bcdiag allows us to do this easily.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"using ROCKS\nusing Random\nusing Distributions\nusing BenchmarkTools\nRandom.seed!(888)\nconst x = rand(Uniform(-5, 5), 1_000_000)\nconst logit = -3.0 .+ 0.5 .* x .+ rand(Normal(0, 0.1), length(x))\nconst prob = @. 1.0 / (1.0 + exp(-logit))\nconst target = rand(length(x)) .<= prob\nnothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"kstest:","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"kstest(target, prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"roc:","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"roc(target, prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"These functions are performant:","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"@benchmark kstest($target, $prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"@benchmark roc($target, $prob)","category":"page"},{"location":"man/bcdiag/#bcdiag","page":"Plots","title":"bcdiag","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"In additional to numeric metrics, often we would like to have plots and tables as part of final model documentation. The bcdiag function allows easy generation of plots and tables.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"Running bcdiag prints a quick summary:","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"mdiag = bcdiag(target, prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"The output structure allows us to create the following plots and tables to understand:","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"the ability of the model to separate the two classes\nthe accuracy of the probability point estimates\nhow to set cutoff for maximum accuracy\nperformance of the model at varying cutoff depth","category":"page"},{"location":"man/bcdiag/#ksplot","page":"Plots","title":"ksplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"ksplot plots the cumulative distribution of class 1 (true positive rate) and class 0 (false positive rate) versus depth.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"ksplot(mdiag)\npng(\"bcd-ksplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"It shows where the maximum separation of the two distributions occur.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#rocplot","page":"Plots","title":"rocplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"rocplot plots the true positive rate vs. false positive rate (depth is implicit).","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"rocplot(mdiag)\npng(\"bcd-rocplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"A perfect model has auc of 1, a random model has auc of 0.5.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#biasplot","page":"Plots","title":"biasplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"Both ksplot and rocplot rely on the ability of the model to rank order the observations, the score value itself doesn't matter. For example, if you took the score and perform any monotonic transform, ks and auc wouldn't change. There are occasions where the score value does matter, where the probabilities need to be accurate, for example, in expected return calculations. Thus, we need to understand whether the probabilities are accurate, biasplot does this by plotting the observed response rate versus predicted response rate to look for systemic bias. This is also called the calibration graph.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"biasplot(mdiag)\npng(\"bcd-biasplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"(Image: )","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"An unbiased model would lie on the diagnonal, systemic shift off the diagonal represents over or under estimate of the true probability.","category":"page"},{"location":"man/bcdiag/#accuracyplot","page":"Plots","title":"accuracyplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"People often refer to (TP + TN) / N as accuracy of the model, that is, the ability to correctly identify correct cases. It is used to compare model performance as well - model with higher accuracy is a better model. For a probability based classifier, a cutoff is required to turn probability to predicted class. So, what is the cutoff value to use to achieve maximum accuracy?","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"There are many approaches to setting the best cutoff, one way is to assign utility values to the four outcomes of [TP, FP, FN, TN] and maximize the sum across different cutoff's. Accuracy measure uses the utility values of [1, 0, 0, 1] giving TP + TN. You can assign negative penalty terms for misclassification as well.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"Note that this is different from kstest - maximum separation on cumulative distribution (normalized to 100%) does not account for class size difference, e.g., class 1 may be only 2% of the cases.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"accuracyplot(mdiag)\npng(\"bcd-accuracyplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#liftcurve","page":"Plots","title":"liftcurve","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"liftcurve plots the actual response and predicted response versus depth, with baserate as 1.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"liftcurve(mdiag)\npng(\"bcd-liftcurve.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"We can easily see where the model is performing better than average, approximately the same as average, or below average.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#cumliftcurve","page":"Plots","title":"cumliftcurve","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"cumliftcurve is similar to liftcurve, the difference is it is a plot of cumulative response rate from the top of the model.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"cumliftcurve(mdiag)\npng(\"bcd-cumliftcurve.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#Tables","page":"Plots","title":"Tables","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"bcdiag uses 100 as the default number of groups, this is good for generating plots above.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"For tables such as decile reports, we may want to run bcdiag with only 10 groups and then generate the tables:","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"mdiag10 = bcdiag(target, prob; groups = 10)","category":"page"},{"location":"man/bcdiag/#liftable","page":"Plots","title":"liftable","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"liftable is the table from which liftcurve is plotted.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"liftable(mdiag10)","category":"page"},{"location":"man/bcdiag/#cumliftable","page":"Plots","title":"cumliftable","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"cumliftable is the cumulative version of liftable.","category":"page"},{"location":"man/bcdiag/","page":"Plots","title":"Plots","text":"cumliftable(mdiag10)","category":"page"},{"location":"man/kstest/#Kolmogorov-Smirnov-Test","page":"KS Test","title":"Kolmogorov-Smirnov Test","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"Kolmogorov-Smirnov test is a test of the equivalence of two distributions. The test is based on finding the maximum separation between the two cumulative distribution functions (CDF) and determining the p-value of the test statistic. The HypothesisTests package has ApproximateTwoSampleKSTest which does this, but, unfortunately, it doesn't tell us the location of maximum separation.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"For binary classifiers, the predicted probabilities of the two classes should be different, thus the interest isn't whether the probability distributions are different, rather, it is how large is the maximal separation and where does it occur.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"Let's generate some data to illustrate the idea.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"using Plots\nusing Random\nusing Distributions\n\nRandom.seed!(123)\n\nn100 = rand(Normal(100, 10), 1000)\nn105 = rand(Normal(105, 10), 1000)\nn120  = rand(Normal(120, 10), 1000)\nn140  = rand(Normal(140, 10), 1000)\n; # hide","category":"page"},{"location":"man/kstest/#Closely-spaced-distributions","page":"KS Test","title":"Closely spaced distributions","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"histogram(n100, nbins = 50, opacity= 0.3)\nhistogram!(n105, nbins = 50, opacity= 0.3, legend = nothing)\npng(\"kstest-1.png\"); nothing # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"We can view their empirical culumative distribution function as follows:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"function viewcdf(pl, v)\n    len = length(v)\n    pl(sort(v), (1:len) ./ len, \n    xlabel = \"sample\", ylabel = \"Probability\", \n    title = \"Empirical Cumluative Distribution\", legend = nothing)\nend\n\nviewcdf(plot, n100)\nviewcdf(plot!, n105)\npng(\"kstest-1cdf.png\"); nothing # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"ROCKS provides a kstest function to find the maximum separation and its location. The required input is a vector designating the two classes and another vector of the values, this is the typical data structure of model scoring on development or validation data.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"using ROCKS\n\ncls = [fill(0, length(n100)); fill(1, length(n105))]\nvalues = [n100; n105]\nkstest(cls, values)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"kstest returns results in a named tuple:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"n, total number of observations\nn1, total number of observations in class 1\nn0, total number of observations in class 0\nbaserate, n1 / n, the incidence rate of class 1\nks, the maximum separation between CDF1 and CDF0, a value between [0, 1]\nksarg, argmax, the value where maximum separation is achieved\nksdep, depth of argmax in the sorted values (default sort is from high to low)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"ks of 0 means the distributions are indistinguishable, ks of 1 says the two distributions are complete separable. These two distributions have negligible separation since they are drawn from the same distribution.","category":"page"},{"location":"man/kstest/#Moderately-separated-distributions","page":"KS Test","title":"Moderately separated distributions","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"We now test on moderate separation:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"histogram(n100, nbins = 50, opacity= 0.3)\nhistogram!(n120, nbins = 50, opacity= 0.3, legend = nothing)\npng(\"kstest-2.png\"); nothing    # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"cls = [fill(0, length(n100)); fill(1, length(n120))]\nvalues = [n100; n120]\nkstest(cls, values)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"There's considerable separation between the classes, and ks is larger than before.","category":"page"},{"location":"man/kstest/#Widely-separated-distributions","page":"KS Test","title":"Widely separated distributions","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"Let's test on widely separately data:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"histogram(n100, nbins = 50, opacity= 0.3)\nhistogram!(n140, nbins = 50, opacity= 0.3, legend = nothing)\npng(\"kstest-3.png\"); nothing    # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"cls = [fill(0, length(n100)); fill(1, length(n140))]\nvalues = [n100; n140]\nkstest(cls, values)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"We can see that the two classes are nearly separable and ks is now quite high at 0.949. These examples illustrate how ks can serve as an indicator of the ability to separate the two classes.","category":"page"},{"location":"#ROCKS.jl","page":"Home","title":"ROCKS.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Two of the commonly used metrics to evaluate the performance of a binary classifier are:","category":"page"},{"location":"","page":"Home","title":"Home","text":"C-statistic (concordance statistic) or Area Under Curve or just ROC ","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Receiver Operating Characteristic)","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"images/rocplot.png\" width=\"500\" />","category":"page"},{"location":"","page":"Home","title":"Home","text":"KS-Statistic (Kolmogorov-Smirnov 2 sample CDF max separation)","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"images/ksplot.png\"/ width=\"500\" />","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package makes it easy to calculate ROC and KS, and produce graphs and tables for documentation purposes.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is installable via its URL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add https://github.com/DaymondLing/ROCKS.jl","category":"page"},{"location":"man/roc/#ROC","page":"ROC","title":"ROC","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"A good binary classifier should have high sensitivity (able to recognize True Positive) and high specificity (able to recognize True Negatives, hence have low False Positive). A plot of the trade-off curve of True Positive Rate versus False Positive Rate at various cutoff probabilities is called the Receiver Operating Characteristic (ROC) curve. One way to quantify performance is by the area under the ROC curve, often abbreviated as AUC or C, many packages compute AUC via numeric integration of the ROC curve. AUC is in the range [0, 1], a perfect model has AUC of 1, a random model has AUC of 0.5, and a perfectly backwards model would have AUC of -1.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"There is another interpretation of AUC which provides more intuition than simply as the area under a curve. If we make all possible pair-wise comparisons between the probabilities of class 1 with class 0, we can count the incidences of:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Concordant: class 1 probability > class 0 probability\nTied: class 1 probability â‰ˆ class 0 probability\nDiscordant: class 1 probability < class 0 probability","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Then we can compute:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"AUC: (Concordant + 0.5 Tied) / (N1 * N0)\nGini: 2AUC - 1, or (Concordant - Discordant) / (N1 * N0)\nGoodman-Kruskal Gamma: (Concordant - Discordant) / (Concordant + Discordant), no penalty for Tied\nKendall's Tau: (Concordant - Discordant) / (0.5 * (N1+N0) * (N1+N0-1))","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"We can interpret AUC as the percentage of time class 1 probabilities is larger than class 0 probabilities (ignoring ties).","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"The mathematical proof can be found at Stack Exchange and Professor David J. Hand's article.","category":"page"},{"location":"man/roc/#Example","page":"ROC","title":"Example","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Create data:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"using ROCKS\nusing Random\nusing Distributions\n\nRandom.seed!(888)\nconst x = rand(Uniform(-5, 5), 1_000_000)\nconst logit = -3.0 .+ 0.5 .* x .+ rand(Normal(0, 0.1), length(x))\nconst prob = @. 1.0 / (1.0 + exp(-logit))\nconst target = rand(length(x)) .<= prob\n; # hide ","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Now compute roc:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"roc(target, prob)","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"roc returns results in a named tuple:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"conc, number of concordant comparisons\ntied, number of tied comparisons\ndisc, number of discordant comparisons\nauc, area under ROC curve, or just area under curve\ngini, 2auc - 1","category":"page"},{"location":"man/roc/#Concordance","page":"ROC","title":"Concordance","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"roc is just a synonym for the concordance function. We can use it in a more general setting of comparing two distributions.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"using Random\nusing Distributions\nusing StatsBase\n\nRandom.seed!(123)\nw1 = rand(Weibull(1.3, 30_000), 100_000)\nw2 = rand(Weibull(1.3, 33_000), 100_000)\n\nmean(w1), mean(w2)","category":"page"},{"location":"man/roc/#Fixed-width-tied-region","page":"ROC","title":"Fixed width tied region","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Values +/- 1,000 are considered ties:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"cls = [fill(0, length(w1)); fill(1, length(w2))]\nvalues = [w1; w2]\nconcordance(cls, values, 1_000)","category":"page"},{"location":"man/roc/#Percentage-width-tied-range","page":"ROC","title":"Percentage width tied range","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Values within 10% are tied:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"pct(x) = 0.9*x, 1.1*x\n\nconcordance(cls, values, pct)","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"In these scenarios, concordance is a measure of how often does individual level comparisions agree with aggregate level comparisons. e.g., if group B on average has more money than group A, when we do individual level comparisons, how often is the group level statement true, tied or false.","category":"page"}]
}
