var documenterSearchIndex = {"docs":
[{"location":"Reference/","page":"Function Reference","title":"Function Reference","text":"CurrentModule = ROCKS","category":"page"},{"location":"Reference/","page":"Function Reference","title":"Function Reference","text":"","category":"page"},{"location":"Reference/","page":"Function Reference","title":"Function Reference","text":"Modules = [ROCKS]","category":"page"},{"location":"Reference/#ROCKS.BCDiag","page":"Function Reference","title":"ROCKS.BCDiag","text":"BCDiag\n\nA structure of diagnostic properties of a Binary Classifier, facilitates summary plots and tables.\n\n\n\n\n\n","category":"type"},{"location":"Reference/#ROCKS.accuracyplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.accuracyplot","text":"accuracyplot(x::BCDiag; util=[1, 0, 0, 1])\n\nUsing util values for [TP, FN, FP, TN], produce accuracy plot and its [max, argmax, argdep].\nDefault util values of [1, 0, 0, 1] gives the standard accuracy value of (TP+TN)/N.\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.bcdiag-Tuple{BitVector, Vector{T} where T}","page":"Function Reference","title":"ROCKS.bcdiag","text":"bcdiag(target, pred; groups = 100, rev = true, tie = 1e-6)\n\nPerform diagnostics of a binary classifier.\ntarget is a 2 level categorical variable, pred is probability of class 1.\ngroups is the number of bins to use for plotting/printing.\nrev = true orders pred from high to low.\ntie is the tolerance of pred where values are considered tied.\n Returns a BCDiag struct which can be used for plotting or printing:\n\nbiasplot is calibration plot of target response rate vs. pred response rate\nksplot produces ksplot of cumulative distributions\nrocplot plots the Receiver Operating Characteristics curve\naccuracyplot plots the accuracy curve with adjustable utility\nliftcurve is the lift curve\ncumliftsurve is the cumulative lift surve\nliftable is the lift table as a DataFrame\ncumliftable is the cumulative lift table as a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.biasplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.biasplot","text":"biasplot(x::BCDiag)\n\nreturn bias calibration plot of x - actual response vs. predicted response\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.concordance","page":"Function Reference","title":"ROCKS.concordance","text":"concordance(class, var, tie)\n\nComputes concordant, tied and discordant pairs.\nclass can be either a BitVector or a 2 level categorical target variable in which case true is defined by the last value in sorted sequence.\nvar is a Vector of predictor, same length as class,\ntie (optional) can be a number (default is 1e-6) that defines a tied region, or it can be a function that when called with a scalar value will return a tuple of lower bound and upper bound of a tied region, useful when you want to do percentage tied region for instance.\n\nPair-wise comparison between class 1 with class 0 values are made as follows:\n\nclass 1 value > class 0 value is Concordant\nclass 1 value â‰ˆ class 0 value (within tie) is Tied\nclass 1 value < class 0 value is Discordant\n\nReturns:\n\nconcordant, number of concordant comparisons\ntied, number of tied comparisons\ndiscordant, number of discordant comparisons\nauroc, or C, is (Concordant + 0.5Tied) / Total comparisons; same as numeric integration of ROC curve\ngini, 2C-1, also known as Somer's D, is (Concordant - Discordant) / Total comparisons\n\nConcordance calculation is the same as numeric integration of the ROC curve, but it allows for fuzzy tied regions which can be useful.\n\nNote:\n\nGoodman-Kruskal Gamma is (Concordant - Discordant) / (Concordant + Discordant)\nKendall's Tau is (Concordant - Discordant) / (0.5 x Total count x (Total count - 1))\n\n\n\n\n\n","category":"function"},{"location":"Reference/#ROCKS.cumliftable-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.cumliftable","text":"cumliftable(x::BCDiag)\n\nreturn cumulative lift table of x as a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.cumliftcurve-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.cumliftcurve","text":"cumliftcurve(x::BCDiag)\n\nreturn cumulative lift curve plot of x - cumulative actual and predicted vs. depth\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.ksplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.ksplot","text":"ksplot(x::BCDiag)\n\nreturn KS plot of x - CDF1 (True Positive) and CDF0 (False Positive) versus depth\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.kstest-Tuple{BitVector, Vector{T} where T}","page":"Function Reference","title":"ROCKS.kstest","text":"kstest(class, var; rev = true)\n\nCalculate empirical 2 sample Kolmogorov-Smirnov statistic and its location.\nclass is a 2 level categorical variable, var is the distribution to analyze.\n\nReturns:\n\nn, total number of observations\nn1, number of observations of class 1\nn0, number of observations of class 0\nbaserate, incidence rate of class 1\nks, the maximum separation between the two cumulative distributions\nksarg, the value of var at which maximum separation is achieved\nksdep, depth of ksarg in the sorted values of var\n\nrev = true counts depth from high value towards low value\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.liftable-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.liftable","text":"liftable(x::BCDiag)\n\nreturn lift table of x as a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.liftcurve-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.liftcurve","text":"liftcurve(x::BCDiag)\n\nreturn lift curve plot of x - actual and predicted versus depth\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.ranks-Tuple{Vector{T} where T}","page":"Function Reference","title":"ROCKS.ranks","text":"ranks(x; groups = 10, rank = tiedrank, rev = false)\n\nReturn a variable which bins x into groups number of bins.\nThe rank keyword allows different ranking method;\nuse rev = true to reverse sort so that small bin number is large value of x.\nMissing values are assigned to group missing.\n\nDefault values of rank = tiedrank and rev = false results in similar grouping as SAS PROC RANK groups=n tied=mean.\n\n\n\n\n\n","category":"method"},{"location":"Reference/#ROCKS.rocplot-Tuple{BCDiag}","page":"Function Reference","title":"ROCKS.rocplot","text":"rocplot(x::BCDiag)\n\nreturn ROC plot of x - CDF1 (True Positive) vs. CDF0 (False Positive)\n\n\n\n\n\n","category":"method"},{"location":"man/bcdiag/#Binary-Classifier-Diagnostics","page":"Plots and Tables","title":"Binary Classifier Diagnostics","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"While kstest and roc provide diagnostic measures for comparing model performance, we may want to produce graphs and tables to  document its performance, bcdiag allows us to do this easily.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"using ROCKS\nusing Random\nusing Distributions\nusing BenchmarkTools\nRandom.seed!(888)\nconst x = rand(Uniform(-5, 5), 1_000_000)\nconst logit = -3.0 .+ 0.5 .* x .+ rand(Normal(0, 0.1), length(x))\nconst prob = @. 1.0 / (1.0 + exp(-logit))\nconst target = rand(length(x)) .<= prob\nnothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"kstest:","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"kstest(target, prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"roc:","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"roc(target, prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"These functions are performant:","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"@benchmark kstest($target, $prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"@benchmark roc($target, $prob)","category":"page"},{"location":"man/bcdiag/#bcdiag","page":"Plots and Tables","title":"bcdiag","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"In additional to numeric metrics, often we would like to have plots and tables as part of final model documentation. The bcdiag function allows easy generation of plots and tables.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"Running bcdiag prints a quick summary:","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"mdiag = bcdiag(target, prob)","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"The output structure allows us to create the following plots and tables to understand:","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"the ability of the model to separate the two classes\nthe accuracy of the probability point estimates\nhow to set cutoff for maximum accuracy\nperformance of the model at varying cutoff depth","category":"page"},{"location":"man/bcdiag/#ksplot","page":"Plots and Tables","title":"ksplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"ksplot plots the cumulative distribution of class 1 (true positive rate) and class 0 (false positive rate) versus depth.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"ksplot(mdiag)\npng(\"bcd-ksplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"It shows where the maximum separation of the two distributions occur.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#rocplot","page":"Plots and Tables","title":"rocplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"rocplot plots the true positive rate vs. false positive rate (depth is implicit).","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"rocplot(mdiag)\npng(\"bcd-rocplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"A perfect model has auc of 1, a random model has auc of 0.5.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#biasplot","page":"Plots and Tables","title":"biasplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"Both ksplot and rocplot rely on the ability of the model to rank order the observations, the score value itself doesn't matter. For example, if you took the score and perform any monotonic transform, ks and auc wouldn't change. There are occasions where the score value does matter, where the probabilities need to be accurate, for example, in expected return calculations. Thus, we need to understand whether the probabilities are accurate, biasplot does this by plotting the observed response rate versus predicted response rate to look for systemic bias. This is also called the calibration graph.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"biasplot(mdiag)\npng(\"bcd-biasplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"(Image: )","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"An unbiased model would lie on the diagnonal, systemic shift off the diagonal represents over or under estimate of the true probability.","category":"page"},{"location":"man/bcdiag/#accuracyplot","page":"Plots and Tables","title":"accuracyplot","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"People often refer to (TP + TN) / N as accuracy of the model, that is, the ability to correctly identify correct cases. It is used to compare model performance as well - model with higher accuracy is a better model. For a probability based classifier, a cutoff is required to turn probability to predicted class. So, what is the cutoff value to use to achieve maximum accuracy?","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"There are many approaches to setting the best cutoff, one way is to assign utility values to the four outcomes of [TP, FP, FN, TN] and maximize the sum across different cutoff's. Accuracy measure uses the utility values of [1, 0, 0, 1] giving TP + TN. You can assign negative penalty terms for misclassification as well.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"Note that this is different from kstest - maximum separation on cumulative distribution (normalized to 100%) does not account for class size difference, e.g., class 1 may be only 2% of the cases.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"accuracyplot(mdiag)\npng(\"bcd-accuracyplot.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#liftcurve","page":"Plots and Tables","title":"liftcurve","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"liftcurve plots the actual response and predicted response versus depth, with baserate as 1.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"liftcurve(mdiag)\npng(\"bcd-liftcurve.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"We can easily see where the model is performing better than average, approximately the same as average, or below average.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#cumliftcurve","page":"Plots and Tables","title":"cumliftcurve","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"cumliftcurve is similar to liftcurve, the difference is it is a plot of cumulative response rate from the top of the model.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"cumliftcurve(mdiag)\npng(\"bcd-cumliftcurve.png\"); nothing # hide","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"(Image: )","category":"page"},{"location":"man/bcdiag/#Tables","page":"Plots and Tables","title":"Tables","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"bcdiag uses 100 as the default number of groups, this is good for generating plots above.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"For tables such as decile reports, we may want to run bcdiag with only 10 groups and then generate the tables:","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"mdiag10 = bcdiag(target, prob; groups = 10)","category":"page"},{"location":"man/bcdiag/#liftable","page":"Plots and Tables","title":"liftable","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"liftable is the table from which liftcurve is plotted.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"liftable(mdiag10)","category":"page"},{"location":"man/bcdiag/#cumliftable","page":"Plots and Tables","title":"cumliftable","text":"","category":"section"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"cumliftable is the cumulative version of liftable.","category":"page"},{"location":"man/bcdiag/","page":"Plots and Tables","title":"Plots and Tables","text":"cumliftable(mdiag10)","category":"page"},{"location":"man/kstest/#Kolmogorov-Smirnov-Test","page":"KS Test","title":"Kolmogorov-Smirnov Test","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"Kolmogorov-Smirnov test is a test of the equivalence of two distributions. The test is based on finding the maximum separation between the two cumulative distribution functions (CDF) and determining the p-value of the test statistic. The HypothesisTests package has ApproximateTwoSampleKSTest which does this, but, unfortunately, it doesn't tell us the location of maximum separation.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"For binary classifiers, the predicted probabilities of the two classes should be different, thus the interest isn't whether the probability distributions are different, rather, it is how large is the maximal separation and where does it occur.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"Let's generate some data to illustrate the idea.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"using Plots\nusing Random\nusing Distributions\n\nRandom.seed!(123)\n\nn100 = rand(Normal(100, 10), 1000)\nn105 = rand(Normal(105, 10), 1000)\nn120  = rand(Normal(120, 10), 1000)\nn140  = rand(Normal(140, 10), 1000)\nnothing # hide","category":"page"},{"location":"man/kstest/#Closely-spaced-distributions","page":"KS Test","title":"Closely spaced distributions","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"histogram(n100, nbins = 50, opacity= 0.3)\nhistogram!(n105, nbins = 50, opacity= 0.3, legend = nothing)\npng(\"kstest-1.png\"); nothing # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"We can view their empirical culumative distribution function as follows:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"function viewcdf(pl, v)\n    len = length(v)\n    pl(sort(v), (1:len) ./ len, \n    xlabel = \"sample\", ylabel = \"Probability\", \n    title = \"Empirical Cumluative Distribution\", legend = nothing)\nend\n\nviewcdf(plot, n100)\nviewcdf(plot!, n105)\npng(\"kstest-1cdf.png\"); nothing # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"ROCKS provides a kstest function to find the maximum separation and its location. The required input is a vector designating the two classes and another vector of the values, this is the typical data structure of model scoring on development or validation data.","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"using ROCKS\n\ncls = [fill(0, length(n100)); fill(1, length(n105))]\nvalues = [n100; n105]\nkstest(cls, values)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"kstest returns results in a named tuple:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"n, total number of observations\nn1, total number of observations in class 1\nn0, total number of observations in class 0\nbaserate, n1 / n, the incidence rate of class 1\nks, the maximum separation between CDF1 and CDF0, a value between [0, 1]\nksarg, argmax, the value where maximum separation is achieved\nksdep, depth of argmax in the sorted values (default sort is from high to low)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"ks of 0 means the distributions are indistinguishable, ks of 1 says the two distributions are complete separable. These two distributions have small separation since they are drawn from distributions with large overlap.","category":"page"},{"location":"man/kstest/#Moderately-separated-distributions","page":"KS Test","title":"Moderately separated distributions","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"We now test on moderate separation:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"histogram(n100, nbins = 50, opacity= 0.3)\nhistogram!(n120, nbins = 50, opacity= 0.3, legend = nothing)\npng(\"kstest-2.png\"); nothing    # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"cls = [fill(0, length(n100)); fill(1, length(n120))]\nvalues = [n100; n120]\nkstest(cls, values)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"There's considerable separation between the classes, and ks is larger than before.","category":"page"},{"location":"man/kstest/#Widely-separated-distributions","page":"KS Test","title":"Widely separated distributions","text":"","category":"section"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"Let's test on widely separately data:","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"histogram(n100, nbins = 50, opacity= 0.3)\nhistogram!(n140, nbins = 50, opacity= 0.3, legend = nothing)\npng(\"kstest-3.png\"); nothing    # hide","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"(Image: )","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"cls = [fill(0, length(n100)); fill(1, length(n140))]\nvalues = [n100; n140]\nkstest(cls, values)","category":"page"},{"location":"man/kstest/","page":"KS Test","title":"KS Test","text":"We can see that the two classes are nearly separable and ks is now quite high at 0.949. These examples illustrate how ks can serve as an indicator of the ability to separate the two classes.","category":"page"},{"location":"#ROCKS.jl","page":"Home","title":"ROCKS.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Two of the commonly used metrics to evaluate the performance of a binary classifier are:","category":"page"},{"location":"","page":"Home","title":"Home","text":"C-statistic (concordance statistic) or Area Under Curve or just ROC ","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Receiver Operating Characteristic)","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"images/rocplot.png\" width=\"500\" />","category":"page"},{"location":"","page":"Home","title":"Home","text":"KS-Statistic (Kolmogorov-Smirnov 2 sample CDF max separation)","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img src=\"images/ksplot.png\"/ width=\"500\" />","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package makes it easy to calculate ROC and KS, and produce graphs and tables for documentation purposes.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is installable via its URL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add https://github.com/DaymondLing/ROCKS.jl","category":"page"},{"location":"man/roc/#ROC","page":"ROC","title":"ROC","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"A good binary classifier should have high sensitivity (able to recognize True Positive, low False Negative) and high specificity (able to recognize True Negatives, low False Positive). A plot of the trade-off curve of True Positive Rate versus False Positive Rate at various cutoff probabilities is called the Receiver Operating Characteristic (ROC) curve. One way to quantify performance is by the area under the ROC curve, often abbreviated as AUC or C.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"AUC is in the range [0, 1], a perfect model has AUC of 1, a random model has AUC of 0.5, and a perfectly backwards model would have AUC of -1.","category":"page"},{"location":"man/roc/#Example","page":"ROC","title":"Example","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Create data:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"using ROCKS\nusing Random\nusing Distributions\n\nRandom.seed!(888)\nconst x = rand(Uniform(-5, 5), 1_000_000)\nconst logit = -3.0 .+ 0.5 .* x .+ rand(Normal(0, 0.1), length(x))\nconst prob = @. 1.0 / (1.0 + exp(-logit))\nconst target = rand(length(x)) .<= prob\nnothing # hide","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Now compute roc:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"roc(target, prob)","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"auc is the area under ROC curve.","category":"page"},{"location":"man/roc/#Concordance","page":"ROC","title":"Concordance","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Many packages compute AUC via numeric integration of area under the ROC curve. There is another interpretation of AUC which provides more intuition than simply as the area under a curve.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"If we make all possible pair-wise comparisons between the probabilities of class 1 with class 0, we can count the incidences of:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Concordant: class 1 probability > class 0 probability\nTied: class 1 probability â‰ˆ class 0 probability\nDiscordant: class 1 probability < class 0 probability","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"We can then compute the following metrics:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"AUC: (Concordant + 0.5 Tied) / (N1 * N0)\nGini: 2AUC - 1, or (Concordant - Discordant) / (N1 * N0)\nGoodman-Kruskal Gamma: (Concordant - Discordant) / (Concordant + Discordant), no penalty for Tied\nKendall's Tau: (Concordant - Discordant) / (0.5 * (N1+N0) * (N1+N0-1))","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"When there are few ties, AUC is the percent of concordant pairs, this is where the name C-statistic or Concordance-statistic came from. The mathematical proof can be found at Stack Exchange and Professor David J. Hand's article.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"In this package, roc is just a synonym for the concordance function, it returns a named tuple:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"conc, number of concordant comparisons\ntied, number of tied comparisons\ndisc, number of discordant comparisons\nauc, area under ROC curve, or just area under curve\ngini, 2auc - 1","category":"page"},{"location":"man/roc/#Fixed-width-tied-region","page":"ROC","title":"Fixed width tied region","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"We can use concordance in the more general setting of comparing two  distributions with control over tied definitions.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Let's create two weibull distributions,","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"using Random\nusing Distributions\nusing StatsBase\n\nRandom.seed!(123)\nw1 = rand(Weibull(1.3, 30_000), 100_000)\nw2 = rand(Weibull(1.3, 33_000), 100_000)\n\nmean(w1), mean(w2)","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"If we consider values within +/- 1,000 as ties:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"cls = [fill(0, length(w1)); fill(1, length(w2))]\nvalues = [w1; w2]\nc = concordance(cls, values, 1_000)","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"We can compute percentages as follows:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"tot = c.conc + c.tied + c.disc\nprintln(\"Concordant %: \", round(c.conc/tot, digits=4),\n        \"\\nTied       %: \", round(c.tied/tot, digits=4),\n        \"\\nDiscordant %: \", round(c.disc/tot, digits=4))","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"We can interpret it as, if cls[2] on aggregate has higher value than cls[1], the statement is true concordant% of the time, the statement is neither true or false tied% of the time, the statement is false discordant% of the time. Whereas the simplistic global statement suggests it is true all the time, we now know the extent to which it is true and can argue that it is in fact false discordant% of the time and assess decisions made based on better insights.","category":"page"},{"location":"man/roc/#Percentage-tied-range","page":"ROC","title":"Percentage tied range","text":"","category":"section"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Rather than a fixed tied region, it may be appropriate to have variable tied region, e.g., when comparing income, it would be better to use a percentage rather than fixed amount.","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"Here's an example where values within 10% are considered as tied:","category":"page"},{"location":"man/roc/","page":"ROC","title":"ROC","text":"c = concordance(cls, values, x -> (0.9*x, 1.1*x))\ntot = c.conc + c.tied + c.disc\nprintln(\"Concordant %: \", round(c.conc/tot, digits=4),\n        \"\\nTied       %: \", round(c.tied/tot, digits=4),\n        \"\\nDiscordant %: \", round(c.disc/tot, digits=4))","category":"page"}]
}
